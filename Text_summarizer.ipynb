{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bdd64f3",
   "metadata": {},
   "source": [
    "# Text summarization using Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903bee03",
   "metadata": {},
   "source": [
    "The following script demonstartes the usage of the Hugging Face Transformers library to perform text summarization using a pre-trained model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9138748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to c:\\Users\\elena.jolkver\\AppDat\n",
      "[nltk_data]     a\\Local\\miniforge3\\envs\\nlp\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import nltk  # Import the Natural Language Toolkit library\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "\n",
    "nltk.download(\"punkt\")  # Download the 'punkt' tokenizer models from NLTK\n",
    "from nltk.tokenize import sent_tokenize  # Import the sentence tokenizer from NLTK\n",
    "\n",
    "from transformers import pipeline, set_seed  # Import the pipeline and set_seed functions from the transformers library\n",
    "\n",
    "\n",
    "from sumy.parsers.plaintext import PlaintextParser  # Import PlainTextParser from the sumy package\n",
    "from sumy.nlp.tokenizers import Tokenizer  # Import Tokenizer from the sumy package\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer  # Import TextRankSummarizer from the sumy package\n",
    "\n",
    "from datasets import load_dataset  # Import functions to load datasets from the datasets library\n",
    "\n",
    "import evaluate # Import the evaluate library for model evaluation\n",
    "\n",
    "import pandas as pd  # Import the pandas library to work with tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62e1c9",
   "metadata": {},
   "source": [
    "Nltk (Natural Language Toolkit) is a comprehensive library for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and more. The 'punkt' tokenizer specifically helps in sentence tokenization, which is the process of dividing a text into a list of its component sentences. \n",
    "\n",
    "The transformers library by Huggingface is a state-of-the-art natural language processing library that provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio (Hugging Face â€“ The AI Community Building the Future., 2025). The 'pipeline' function simplifies the implementation of complex models for various NLP tasks, including text generation and summarization.\n",
    "\n",
    "Sumy is a Python library used for text summarization. It offers several algorithms for extracting summaries from text documents. The PlaintextParser is used to read and parse plain text files. TextRankSummarizer is an implementation of the TextRank algorithm, a graph-based summarization technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1b5ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama's full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama's remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there's no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team's final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: 'This menace must be confronted' Obama's senior advisers have debated the next steps to take, and the president's comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament's vote against military action earlier this week was a blow to Obama's hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria's alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It's unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama's speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama's announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama's decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama's fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama's speech in a Twitter post Saturday. \"I understand and support Barack Obama's position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we're just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria's neighbors think? Why Russia, China, Iran stand by Assad . Syria's government unfazed . After Obama's speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria's prime minister appeared unfazed by the saber-rattling. \"The Syrian Army's status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama's address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria's ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don't know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark 'disaster' Opinion: Why strikes in Syria are a bad idea .\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('ccdv/cnn_dailymail', '3.0.0', split='train[:1]', trust_remote_code = True)\n",
    "\n",
    "# Access the first article\n",
    "first_article = dataset[0]\n",
    "print(first_article['article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4f1ba",
   "metadata": {},
   "source": [
    "We have selected the CNN/DailyMail dataset (Hermann et al., 2015) for our analysis of summarization models. This dataset includes approximately 300,000 pairs of news articles and their corresponding summaries. These summaries are derived from the bullet points that CNN and the DailyMail add to their articles. A notable feature of this dataset is that the summaries are not mere excerpts but are instead abstractive, generating new sentences that encapsulate the essence of the articles.\n",
    "\n",
    "For illustrative purposes, we will apply our summarization techniques to a single article. Lengthy articles present a significant challenge to most transformer models due to their typical context size limitation of about 1,000 tokens, which equates to several paragraphs. A common, albeit rudimentary, strategy to manage this constraint is to truncate texts that exceed the model's context size. Although crucial content might reside towards the end of the text, we must navigate this limitation of the model architectures for now, thereby limiting the article to the first 2000 characters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cddfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = dataset[\"article\"][:2000]  # Get the first 2000 characters of the article in the training dataset\n",
    "sample_text = \" \".join(sample_text)\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57890ab",
   "metadata": {},
   "source": [
    "In the absence of human-generated \"true\" summaries within the text corpus, we can create a reference point by establishing a simple baseline. This baseline allows us to compare the machine-generated summaries against a consistent benchmark. To achieve this, we extract the first three sentences of the text to serve as our baseline summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91b178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}  # Initialize an empty dictionary to store summaries\n",
    "\n",
    "summaries[\"baseline\"] = \"\\n\".join(tokenizer.tokenize(sample_text)[:3])  # Generate a baseline summary and store it in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc22e1",
   "metadata": {},
   "source": [
    "The baseline summary, extracted as the first three sentences of the article, already provides a concise encapsulation of the key events: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76342e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S.\\nPresident Barack Obama wants lawmakers to weigh in on whether to use military force in Syria.\\nObama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[\"baseline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a5860",
   "metadata": {},
   "source": [
    "We now proceed with generating a summary using the classical algorithm provided by the Sumy library. One of the key algorithms provided by Sumy is the TextRankSummarizer, which implements the TextRank algorithm. TextRank is a classical unsupervised algorithm inspired by Google's PageRank method used for ranking web pages. As it doesnâ€™t require pre-labeled data or training, it is versatile option when large annotated datasets aren't available. Its effectiveness in summarizing text, especially when domain-specific training data is scarce, makes it a valuable tool in the toolkit of text summarization techniques. By using the TextRankSummarizer from the Sumy library, we can efficiently generate summaries that aim to capture the essential information and main points of the source documents without needing extensive computational resources or training data.\n",
    "Here's how TextRank operates in the context of text summarization:\n",
    "\n",
    "1. Graph-Based Approach: TextRank constructs a graph where sentences are nodes. The edges between sentences are weighted based on the similarity between sentences, typically computed using measures like cosine similarity on word vectors.\n",
    "\n",
    "2. Sentence Representation: Sentences in the text are represented as nodes in the graph, and the algorithm establishes connections (edges) between these nodes based on semantic similarity; the more similar two sentences are, the stronger the connection.\n",
    "\n",
    "3. Ranking Sentences: Once the graph is built, the TextRank algorithm applies a ranking process similar to PageRank to score the nodes (sentences). This process iteratively refines the score of each sentence based on its connections and the score of the connected sentences.\n",
    "\n",
    "4. Extracting Key Sentences: After the ranking process converges, the sentences with the highest scores are extracted as the summary. Typically, the top-ranked sentences are selected to form a coherent and concise summary of the original text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f25a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "NLTK tokenizers are missing or the language is not supported.\nDownload them by following command: python -c \"import nltk; nltk.download('punkt')\"\nOriginal error was:\n\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\elena.jolkver/nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\sumy\\nlp\\tokenizers.py:172\u001b[39m, in \u001b[36mTokenizer._get_sentence_tokenizer\u001b[39m\u001b[34m(self, language)\u001b[39m\n\u001b[32m    171\u001b[39m     path = to_string(\u001b[33m\"\u001b[39m\u001b[33mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.pickle\u001b[39m\u001b[33m\"\u001b[39m) % to_string(language)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mLookupError\u001b[39;00m, zipfile.BadZipfile) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\nltk\\data.py:823\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path_.startswith(\u001b[33m\"\u001b[39m\u001b[33mtokenizers/punkt\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mswitch_punkt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m path_.startswith(\u001b[33m\"\u001b[39m\u001b[33mchunkers/maxent_ne_chunker\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\nltk\\data.py:678\u001b[39m, in \u001b[36mswitch_punkt\u001b[39m\u001b[34m(lang)\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PunktTokenizer \u001b[38;5;28;01mas\u001b[39;00m tok\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtok\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1743\u001b[39m PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\elena.jolkver/nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m parser = PlaintextParser.from_string(sample_text, tokenizer = \u001b[43mTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menglish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Use PlainTextParser to parse the sample text\u001b[39;00m\n\u001b[32m      2\u001b[39m summarizer = TextRankSummarizer()  \u001b[38;5;66;03m# Initialize the TextRank summarizer\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Collect the summary sentences in a list\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\sumy\\nlp\\tokenizers.py:160\u001b[39m, in \u001b[36mTokenizer.__init__\u001b[39m\u001b[34m(self, language)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28mself\u001b[39m._language = language\n\u001b[32m    159\u001b[39m tokenizer_language = \u001b[38;5;28mself\u001b[39m.LANGUAGE_ALIASES.get(language, language)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28mself\u001b[39m._sentence_tokenizer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_sentence_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28mself\u001b[39m._word_tokenizer = \u001b[38;5;28mself\u001b[39m._get_word_tokenizer(tokenizer_language)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\sumy\\nlp\\tokenizers.py:174\u001b[39m, in \u001b[36mTokenizer._get_sentence_tokenizer\u001b[39m\u001b[34m(self, language)\u001b[39m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m nltk.data.load(path)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mLookupError\u001b[39;00m, zipfile.BadZipfile) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\n\u001b[32m    175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNLTK tokenizers are missing or the language is not supported.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"Download them by following command: python -c \"import nltk; nltk.download('punkt')\"\\n\"\"\"\u001b[39;00m\n\u001b[32m    177\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOriginal error was:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m    178\u001b[39m     )\n",
      "\u001b[31mLookupError\u001b[39m: NLTK tokenizers are missing or the language is not supported.\nDownload them by following command: python -c \"import nltk; nltk.download('punkt')\"\nOriginal error was:\n\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\elena.jolkver/nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Local\\\\miniforge3\\\\envs\\\\nlp\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\elena.jolkver\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "parser = PlaintextParser.from_string(sample_text, tokenizer = Tokenizer(\"english\"))  # Use PlainTextParser to parse the sample text\n",
    "summarizer = TextRankSummarizer()  # Initialize the TextRank summarizer\n",
    "\n",
    "# Collect the summary sentences in a list\n",
    "summary_sentences = []  # Initialize an empty list to store summary sentences\n",
    "for sentence in summarizer(parser.document, 5):  # Generate summary sentences using the TextRank summarizer\n",
    "    summary_sentences.append(str(sentence))  # Append each summary sentence to the list\n",
    "\n",
    "# Join the sentences to form a single summary string\n",
    "summaries[\"sumy\"] = \"\\n\".join(summary_sentences)  # Store the generated summary in the dictionary\n",
    "\n",
    "# Print the summary (optional)\n",
    "print(summaries[\"sumy\"])  # Print the summary generated by the TextRank summarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f4975",
   "metadata": {},
   "source": [
    "In the final step, we employ three different large language models (LLMs) for summarization: GPT, BART, and a lightweight version of DeepSeek. Among these, GPT-2 and DeepSeek serve as general-purpose LLMs. We prompt these models by appending \"TL;DR:\" to the article, which is shorthand for \"too long; didnâ€™t read\" and commonly signals a brief summary. Language models recognize this due to its frequent occurrence in training data, interpreting it as an instruction to summarize. This allows for conditional generation, where the model, given this prefix, produces the subsequent words, forming the summary. In contrast, the specific BART model employed here has been fine-tuned on the CNN/DailyMail dataset for summarization tasks. Consequently, BART acts as a form of positive control in our experiment, given its prior training on the very dataset we are utilizing for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba46841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d2dc916ecc475d8605ae5a7d3ea8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\elena.jolkver\\.cache\\huggingface\\hub\\models--gpt2-xl. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# GPT2 summary\u001b[39;00m\n\u001b[32m      2\u001b[39m set_seed(\u001b[32m42\u001b[39m)  \u001b[38;5;66;03m# Set the random seed for reproducibility\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m pipe = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt2-xl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Initialize a text generation pipeline with the GPT-2 XL model\u001b[39;00m\n\u001b[32m      4\u001b[39m query = sample_text + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTL;DR:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Create a query for the GPT-2 model\u001b[39;00m\n\u001b[32m      5\u001b[39m pipe_out = pipe(query, max_new_tokens=\u001b[32m1000\u001b[39m, clean_up_tokenization_spaces=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Generate text using the GPT-2 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:942\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    941\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m model_config = model.config\n\u001b[32m    953\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\elena.jolkver\\AppData\\Local\\miniforge3\\envs\\nlp\\Lib\\site-packages\\transformers\\pipelines\\base.py:243\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[33;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[32m    219\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m \u001b[33;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m     )\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    249\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_from_pipeline\u001b[39m\u001b[33m\"\u001b[39m] = task\n",
      "\u001b[31mRuntimeError\u001b[39m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "# GPT2 summary\n",
    "set_seed(42)  # Set the random seed for reproducibility\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")  # Initialize a text generation pipeline with the GPT-2 XL model\n",
    "query = sample_text + \"\\nTL;DR:\\n\"  # Create a query for the GPT-2 model\n",
    "pipe_out = pipe(query, max_new_tokens=1000, clean_up_tokenization_spaces=True)  # Generate text using the GPT-2 model\n",
    "summaries[\"gpt2\"] = \"\\n\".join(  # Store the generated summary in the dictionary\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(query) :]))  # Tokenize the generated text into sentences\n",
    "del pipe\n",
    "del pipe_out\n",
    "del query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615bdf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_seed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-1-c397c32ebec1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m# DeepSeek Summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\u001b[0m  \u001b[0;31m# Define the model name for the DeepSeek model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the random seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Initialize a text generation pipeline with the DeepSeek model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nTL;DR:\\n\"\u001b[0m  \u001b[0;31m# Create a query for the DeepSeek model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'set_seed' is not defined"
     ]
    }
   ],
   "source": [
    "# DeepSeek Summary\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"  # Define the model name for the DeepSeek model\n",
    "set_seed(42)  # Set the random seed for reproducibility\n",
    "pipe = pipeline(\"text-generation\", model=model_name)  # Initialize a text generation pipeline with the DeepSeek model\n",
    "query = sample_text + \"\\nTL;DR:\\n\"  # Create a query for the DeepSeek model\n",
    "pipe_out = pipe(query, max_new_tokens=1000, clean_up_tokenization_spaces=True)  # Generate text using the DeepSeek model\n",
    "summaries[\"DeepSeek\"] = \"\\n\".join(  # Store the generated summary in the dictionary\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(query) :]))  # Tokenize the generated text into sentences\n",
    "del pipe\n",
    "del pipe_out\n",
    "del query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25391ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8f8873803f96>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mpipe_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
     ]
    }
   ],
   "source": [
    "#BART summary\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")  # Initialize a summarization pipeline with the BART model\n",
    "pipe_out = pipe(sample_text)  # Generate a summary using the BART model\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))  # Store the generated summary in the dictionary\n",
    "del pipe\n",
    "del pipe_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"In the men's 4x100 relay, Usain Bolt secured his third gold medal in Moscow, defeating Justin Gatlin, resulting in Jamaica's victory.\\nThe U.S. team took second, while Canada and Britain finished third and fourth, respectively.\\nThe relay was won by Bolt with Ashmeade providing the baton, and Bolt successfully took control of the baton from Gatlin.\\nThe individual performances in the sprint events also contributed to Jamaica's dominance.\\n</think>\\n\\nIn the men's 4x100m relay, Usain Bolt secured his third gold medal in Moscow, defeating Justin Gatlin, resulting in Jamaica's victory.\\nThe U.S. team took second, while Canada and Britain finished third and fourth, respectively.\\nThe relay was won by Bolt with Ashmeade providing the baton, and Bolt successfully took control of the baton from Gatlin.\\nThe individual performances in the sprint events also contributed to Jamaica's dominance.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[\"DeepSeek\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1936c4",
   "metadata": {},
   "source": [
    "Comparing summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TAXT\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
      "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
      "The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
      "The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles.\n",
      "The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital.\n",
      "\"I'm proud of myself and I'll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics.\n",
      "Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems.\n",
      "Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt.\n",
      "Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple.\n",
      "Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds.\n",
      "Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover.\n",
      "The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team.\n",
      "Fraser-Pryce, like Bolt ag\n",
      "\n",
      "HUMAN SUMMARY\n",
      "Usain Bolt wins third gold of world championship .\n",
      "Anchors Jamaica to 4x100m relay victory .\n",
      "Eighth gold at the championships for Bolt .\n",
      "Jamaica double up in women's 4x100m relay .\n",
      "\n",
      "BASELINE\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
      "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
      "The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
      "\n",
      "GPT2\n",
      "Bolt finished in style by winning the final sprint event in Moscow.\n",
      "There is still a few sprint events to go before Friday's final but so far this final gold should stand as a world record.\n",
      "\n",
      "DEEPSEEK\n",
      "In the men's 4x100 relay, Usain Bolt secured his third gold medal in Moscow, defeating Justin Gatlin, resulting in Jamaica's victory.\n",
      "The U.S. team took second, while Canada and Britain finished third and fourth, respectively.\n",
      "The relay was won by Bolt with Ashmeade providing the baton, and Bolt successfully took control of the baton from Gatlin.\n",
      "The individual performances in the sprint events also contributed to Jamaica's dominance.\n",
      "</think>\n",
      "\n",
      "In the men's 4x100m relay, Usain Bolt secured his third gold medal in Moscow, defeating Justin Gatlin, resulting in Jamaica's victory.\n",
      "The U.S. team took second, while Canada and Britain finished third and fourth, respectively.\n",
      "The relay was won by Bolt with Ashmeade providing the baton, and Bolt successfully took control of the baton from Gatlin.\n",
      "The individual performances in the sprint events also contributed to Jamaica's dominance.\n",
      "\n",
      "BART\n",
      "Usain Bolt wins his third gold of the world championships in Moscow.\n",
      "Bolt anchors Jamaica to victory in the men's 4x100m relay.\n",
      "The 26-year-old has now won eight gold medals at world championships.\n",
      "Jamaica's women also win gold in the relay, beating France in the process.\n",
      "\n",
      "SUMY\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
      "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
      "The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles.\n",
      "The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital.\n",
      "Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TEXT\")\n",
    "for sentence in sent_tokenize(sample_text):\n",
    "    print(sentence)\n",
    "print(\"\")\n",
    "\n",
    "print(\"HUMAN SUMMARY\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78b7b9",
   "metadata": {},
   "source": [
    "But which of these summaries comes closest to the reference summary? To this end, we evaluate the results with the ROUGE metric set, which measures the overlap of n-grams between the machine-generated and reference summaries.\n",
    "\n",
    "- ROUGE-1 measures the overlap of unigrams (single words) between the generated and reference summary , implying the generated summary captures more key terms from the reference.\n",
    "\n",
    "- ROUGE-2 assesses the overlap of bigrams (two-word sequences), suggesting more phrase-level fidelity and detail in the generated summary relative to the reference.\n",
    "\n",
    "- ROUGE-L considers the longest common subsequence, highlighting fluency and coherence.\n",
    "\n",
    "- ROUGE-Lsum is a variant of ROUGE-L specifically tuned for summarization tasks, assessing sentence splits, a higher score suggests a better overall structural and sentence-level match to the reference summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6587aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = load_metric(\"rouge\")  # Load the ROUGE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5783fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1619861291688594,\n        \"min\": 0.1954022988505747,\n        \"max\": 0.5822784810126583,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.21212121212121213,\n          0.21857923497267756,\n          0.1954022988505747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07839629450674626,\n        \"min\": 0.0,\n        \"max\": 0.20779220779220778,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0,\n          0.055248618784530384,\n          0.046511627906976744\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1396965689588945,\n        \"min\": 0.12121212121212122,\n        \"max\": 0.45569620253164556,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.12121212121212122,\n          0.13114754098360656,\n          0.14942528735632185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13866241782963082,\n        \"min\": 0.1724137931034483,\n        \"max\": 0.5063291139240508,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.21212121212121213,\n          0.18579234972677597,\n          0.1724137931034483\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d6dbc8c0-cbb2-4826-a4f4-4f4d784d0bff\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek</th>\n",
       "      <td>0.195402</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.506329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sumy</th>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.185792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6dbc8c0-cbb2-4826-a4f4-4f4d784d0bff')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d6dbc8c0-cbb2-4826-a4f4-4f4d784d0bff button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d6dbc8c0-cbb2-4826-a4f4-4f4d784d0bff');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-82c7a39a-118d-442e-9b1b-0fc03cefd1b9\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82c7a39a-118d-442e-9b1b-0fc03cefd1b9')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-82c7a39a-118d-442e-9b1b-0fc03cefd1b9 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.303571  0.090909  0.214286   0.232143\n",
       "gpt2      0.212121  0.000000  0.121212   0.212121\n",
       "DeepSeek  0.195402  0.046512  0.149425   0.172414\n",
       "bart      0.582278  0.207792  0.455696   0.506329\n",
       "sumy      0.218579  0.055249  0.131148   0.185792"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]  # Get the reference summary from the dataset\n",
    "records = []  # Initialize an empty list to store ROUGE scores\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]  # Define the names of the ROUGE metrics\n",
    "\n",
    "for model_name in summaries:  # Iterate over the generated summaries\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)  # Add the prediction and reference to the ROUGE metric\n",
    "    score = rouge_metric.compute()  # Compute the ROUGE scores\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)  # Create a dictionary of ROUGE scores\n",
    "    records.append(rouge_dict)  # Append the ROUGE scores to the list\n",
    "\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())  # Create a DataFrame from the ROUGE scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b5199",
   "metadata": {},
   "source": [
    "Looking at the results we can make several conclusions: \n",
    "\n",
    "1. Baseline (Three-Sentence Summary): ROUGE-1: 0.30 and ROUGE-L: 0.21 indicate that while the baseline method captures some key words from the reference summary, it lacks depth in fluency (ROUGE-L shows limited coherence). ROUGE-2: 0.09 is relatively low, suggesting a lack of capturing phrase-level information.\n",
    "\n",
    "2. GPT-2: ROUGE-1: 0.21 shows reduced unigram overlap compared to the baseline, which might mean GPT-2 generated broader text rather than sticking to precision words. ROUGE-2: 0.00 indicates GPT-2 did not capture any bigram matches, suggesting generated summaries missed critical phrase-level consistency. ROUGE-L: 0.12 suggests lesser fluency and coherence than the baseline.\n",
    "\n",
    "3. DeepSeek: ROUGE-1: 0.19 and ROUGE-2: 0.04, both lower than the baseline, showing minimal key content and phrase overlap.\n",
    "\n",
    "4. BART: ROUGE-1: 0.58 and ROUGE-2: 0.20 are significantly higher than other models, highlighting BARTâ€™s effectiveness in retaining both key terms and phrase-level details. ROUGE-L: 0.45 and ROUGE-Lsum: 0.50 demonstrate strong fluency, coherence, and effectiveness in summarizing content akin to the reference.\n",
    "\n",
    "5. Sumy (TextRank): ROUGE-1: 0.21 and ROUGE-2: 0.05 slightly outperform GPT-2 and DeepSeek, indicating better capture of key terms and some phrases. ROUGE-L: 0.13 suggests moderate coherence.\n",
    "\n",
    "BART performs best across all ROUGE metrics, which is not surprising given that it has been pre-trained specifically on the CNN/DailyMail dataset. This pre-training allows BART to generate summaries with extensive content overlap and coherence when compared to the reference summaries. However, its high performance should be viewed in the context of its familiarity with the dataset, suggesting that BART may be particularly well-suited for tasks involving similar data but may not generalize as well to entirely new datasets without further fine-tuning. Furthermore we see that GPT-2 and (a slim version of) DeepSeek perform comparably, while the classical method is performing in a comparable range as LLM models. \n",
    "\n",
    "In summary, the performance analysis of different summarization approaches highlights the importance of model-data alignment in achieving effective results. BARTâ€™s remarkable performance underscores the advantages of using models fine-tuned on specific datasets, though with the caveat of potentially limited generalizability. Meanwhile, GPT-2 and DeepSeek illustrate the capabilities of general LLMs, and the classical TextRank approach remains a viable option, especially in contexts lacking expansive computational resources or annotated data. As you consider implementing these techniques, balance model selection with the specific needs and constraints of your intended application, and be mindful of the potential need for fine-tuning to optimize performance across diverse datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
