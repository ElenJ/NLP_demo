{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbhfbO3cgAOwFcniWP8PhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElenJ/NLP_demo/blob/main/NLP_processing_wTranformers_Tunstall_Ch2_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMbqYr2W9SGi"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer # automatically retrieves model's configuration, weights, vocab\n",
        "from transformers import AutoModel # to load weights from pretrained model\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = load_dataset(\"emotion\")\n",
        "emotions"
      ],
      "metadata": {
        "id": "afUVlc-_9ZsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train data\n",
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "id": "VIPwYLlo9gQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert emotions to pandas df\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "\n",
        "def label_int2str(row):\n",
        "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8cHkg6kq9onK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at label distribution\n",
        "df[\"label_name\"].value_counts(ascending=True).plot.barh(title=\"Label distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oUhH0qKN_en0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is imbalanced and actually requires balancing of the classes to train a proper classifyer. TODO for later."
      ],
      "metadata": {
        "id": "MfAUhSCD_7jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "m4_JYwsKA_Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at the length of the texts, as this impacts selection of transformer, which has a certain maximum content size\n",
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False, color=\"black\")\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HRB87faDADwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average tweet length of ~15 words is below the maximum content size of transformer models. We can go on, not fearing the need to truncate text and lose information."
      ],
      "metadata": {
        "id": "5iCleDcuBmiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format() # reset format, don't need to have it as pandas anymore"
      ],
      "metadata": {
        "id": "7elJyDcWB5Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "JmJudrzyP-0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "eIxskJFwQC03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
        "print(tokenize(emotions[\"train\"][:2])) # demo for one"
      ],
      "metadata": {
        "id": "dmcvUBRMMy9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "zEWeHjwQNXRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a text classifyer"
      ],
      "metadata": {
        "id": "HX-BUMyrOsew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = AutoModel.from_pretrained(model_ckpt).to(device)\n"
      ],
      "metadata": {
        "id": "eVwsRKMzOPbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy example\n",
        "text =\"this is a test\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"input tensor shape: {inputs['input_ids'].size()}\")\n",
        "#torch.Size([1, 6]) --> [batch size, tokens]"
      ],
      "metadata": {
        "id": "InCquO2pQmig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the input on same device\n",
        "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
        "with torch.no_grad(): # disable automatic calculations of the gradient, reduces memory footprint of the gradient\n",
        "  outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "BIrJcyDCQ2Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state.size()\n",
        "# [batch, tockens, hidden_dim], a 768-dim vector is returned for each of 6 input tokens.\n",
        "# For classification, it is common practice to use the hidden state associated with the [CLS] token as input feature\n",
        "# [CLS] is at the start of each sequence\n"
      ],
      "metadata": {
        "id": "xD6uYzaNRjYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state[:,0].size()"
      ],
      "metadata": {
        "id": "IbnD4dtiS9RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve last hidden state for my emotions dataset\n",
        "def extract_hidden_states(batch):\n",
        "  # Place model inputs on device\n",
        "  inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
        "  # extract last hidden state\n",
        "  with torch.no_grad():\n",
        "    last_hidden_state = model(**inputs).last_hidden_state\n",
        "  # return vector for [CLS] token\n",
        "  return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()} # map method requires teh function to return a python or numpy object when using batched inputs"
      ],
      "metadata": {
        "id": "gpqzACY5T_19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as the model expects tensors as input, need to convert input_ids and attention_mask to \"torch\" format\n",
        "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "# now we can extract hidden states:\n",
        "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True) # default batch size 1000 used"
      ],
      "metadata": {
        "id": "Jt6XXvEbWH-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function has added hidden_state column to emotions\n",
        "emotions_hidden[\"train\"].column_names"
      ],
      "metadata": {
        "id": "3GYQSPdFWxCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can train the classifyer based on the last hidden state\n",
        "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
        "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
        "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
        "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "4PzM9dwImppo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recheck the input, by visualizing it\n",
        "from umap import UMAP\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# scale features\n",
        "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
        "# reduce dimensionality\n",
        "mapper = UMAP(n_components=2, metric = \"cosine\").fit(X_scaled)\n",
        "# cerate a dataFRame of 2D embeddings\n",
        "db_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
        "db_emb[\"label\"] = y_train\n",
        "db_emb.head()"
      ],
      "metadata": {
        "id": "eudH3eV2nURc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title X vs Y\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "db_emb.plot(kind='scatter', x='X', y='Y', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "_Pwnos9It2zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
        "emotions_labels = emotions[\"train\"].features[\"label\"].names\n",
        "\n",
        "for i, (label, cmap) in enumerate(zip(emotions_labels, cmaps)):\n",
        "  db_emb_filtered = db_emb.query(f\"label == {i}\")\n",
        "  axes[i].hexbin(db_emb_filtered[\"X\"], db_emb_filtered[\"Y\"], cmap = cmap, gridsize = 20, linewidths = (0,))\n",
        "  axes[i].set_title(label)\n",
        "  axes[i].set_xticks([])\n",
        "  axes[i].set_yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r0CtXNNdt9st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model\n",
        "lr_clf = LogisticRegression(max_iter=3000)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "1NvENRYrv1Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare this to a baseline classifyer\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "dummy_clf.score(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "vtcJru42wKjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "  cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "  fig, ax = plt.subplots(figsize=(6,6))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "  plt.title(\"Normalized confusion matrix\")\n",
        "  plt.show()\n",
        "\n",
        "y_preds = lr_clf.predict(X_valid)\n",
        "plot_confusion_matrix(y_preds, y_valid, emotions[\"train\"].features[\"label\"].names)"
      ],
      "metadata": {
        "id": "aNCVCYfWwtXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning"
      ],
      "metadata": {
        "id": "Zizogt7Sxlrr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-ZzScOrxK4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}